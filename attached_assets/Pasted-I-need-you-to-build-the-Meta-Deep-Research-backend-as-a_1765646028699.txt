I need you to build the "Meta-Deep Research" backend as a Replit Background Worker.

**Your Goal:**
Implement a robust, persistent LangGraph application that orchestrates three external Deep Research APIs (Gemini, OpenAI, Perplexity) in parallel.

**Key Requirements:**
1.  **Unified Async Architecture:** Every agent must use the "Submit -> Poll -> Sleep" loop. Do NOT use synchronous blocking calls (like standard `chat.completions`) for the deep research models, or the Replit container will time out.
2.  **Specific API Nuances:**
    * For **Gemini**: Use the `google-genai` library (Interactions API).
    * For **OpenAI**: Use the `/v1/responses` API with `background=True`.
    * For **Perplexity**: Use the `/async` endpoint.
3.  **Persistence:** Initialize `AsyncSqliteSaver` with `sqlite:///replit_state.db`. This is critical so the research resumes if the container restarts.
4.  **Security:** Access all API keys via `os.environ`. Do not hardcode secrets.
5.  **Output:** Provide the `main.py` (FastAPI server + Graph definition) and the correct `replit.nix` configuration.

**Step-by-Step Implementation Plan:**
1.  **Environment:** Configure `replit.nix` and `pyproject.toml` first to ensure `google-genai` and `libxcrypt` are available.
2.  **State:** Define the `TypedDict` schemas.
3.  **Nodes:** Implement the specific "Submit" and "Check" functions for each of the 3 providers.
4.  **Graph:** Build the `StateGraph` with the Supervisor routing and parallel branches.
5.  **Server:** Wrap the graph in a simple FastAPI app (`POST /research`, `GET /status/{run_id}`) so I can poll it.

Let's build this step-by-step, starting with the environment configuration.

# Meta-Deep Research Architecture

## 1. System Topology
A "Supervisor-Worker" agentic system using LangGraph.
- **Supervisor:** Classifies query and routes to 1-3 parallel sub-agents.
- **Workers:** Three distinct "Deep Research" APIs running in parallel.
- **Synthesizer:** Merges the 3 reports into one final consensus report using Claude 4.5 Sonnet.

## 2. The Unified Async Polling Pattern
**CRITICAL:** Do NOT use blocking synchronous calls. All agents follow this state machine:
1. **Submit Node:** Call API with `background=True` (or async equivalent). Get `job_id`.
2. **Check Node:** Poll status endpoint.
3. **Wait Logic:** If `status == "running"`, sleep for 30s (non-blocking) and loop back to Check.

## 3. Sub-Agent Specifications
| Agent | Model ID | Endpoint Logic |
| :--- | :--- | :--- |
| **Gemini** | `gemini-3-pro-preview` | Use `google-genai` SDK (v1.0). `client.interactions.create(..., background=True)`. |
| **OpenAI** | `o3-deep-research` | Use `client.responses.create(..., background=True)`. Do NOT use `chat.completions`. |
| **Perplexity** | `sonar-deep-research` | Use `httpx` to POST `https://api.perplexity.ai/async/chat/completions`. |

## 4. Infrastructure & Persistence
- **Deployment:** Replit Background Worker (keeps `asyncio` loop alive).
- **Persistence:** Use `AsyncSqliteSaver` pointing to `sqlite:///replit_state.db`.
- **Sleep:** Use `await asyncio.sleep(30)`, NEVER `time.sleep()`.

## 5. State Schema
```python
class SubAgentState(TypedDict):
    status: str # "polling", "completed", "failed"
    job_id: Optional[str]
    output: Optional[str]

class MetaResearchState(TypedDict):
    user_query: str
    gemini_data: SubAgentState
    openai_data: SubAgentState
    perplexity_data: SubAgentState
    consensus_report: str
	
# Meta-Deep Research UI Specification

## 1. Tech Stack
- **Framework:** React (Vite)
- **Styling:** Tailwind CSS
- **Icons:** Lucide-React (crucial for status visualization)
- **Markdown:** `react-markdown` (to render the final report)
- **API Client:** `axios` or native `fetch`

## 2. Core UX Flow
1. **Input:** User types a query and clicks "Start Research".
2. **Handshake:** UI POSTs to `/research`. Backend returns `run_id`.
3. **Polling Loop:** UI enters a `setInterval` loop (every 3s), calling `GET /status/{run_id}`.
4. **Visual State:** The UI maps the backend JSON state directly to visual cards.

## 3. The "Agent Card" Component
Each of the 3 agents (Gemini, OpenAI, Perplexity) needs a card component that reacts to the `status` field in the backend response:
- **Status: "idle"** -> Opacity 50%, "Waiting for assignment".
- **Status: "running/polling"** -> Animated Spinner, "Agent Working...", display `job_id` if available.
- **Status: "completed"** -> Green Border, Checkmark Icon, "Report Ready". Add a "Show/Hide Raw Data" toggle to see the raw text from that specific agent.
- **Status: "failed"** -> Red Border, Error Icon, display `error` message.

## 4. Data Mapping (Backend -> Frontend)
The backend `GET /status/{run_id}` returns the full `MetaResearchState`. Map it as follows:

| Backend Field | UI Component |
| :--- | :--- |
| `research_plan` | **Strategy Panel:** "Supervisor's Plan: [value]" |
| `gemini_data.status` | **Gemini Card:** Controls the loading state/badge. |
| `openai_data.status` | **OpenAI Card:** Controls the loading state/badge. |
| `perplexity_data.status`| **Perplexity Card:** Controls the loading state/badge. |
| `consensus_report` | **Main Result:** Render this markdown only when it is not null. |

## 5. Resilience
- If the user refreshes the page, the UI should ideally check for an active `run_id` in `localStorage` and resume polling (optional but recommended).
	
# Dependency Guide

## replit.nix
Must include system libraries for Python crypto and SQLite:
- `pkgs.libxcrypt`
- `pkgs.sqlite`
- `pkgs.zlib`

## Python Packages
- `langgraph`
- `langchain`
- `google-genai` (Note: This is the new v1.0 SDK, NOT `google-generativeai`)
- `openai` (v1.59+)
- `anthropic`
- `httpx`
- `fastapi`
- `uvicorn`